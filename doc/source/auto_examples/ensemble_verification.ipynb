{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verification of an ensemble nowcast\n\nThe script shows how to run verification experiments for ensemble precipitation\nnowcasting with pysteps.\n\nMore info: https://pysteps.github.io/\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import csv\nimport datetime\nimport matplotlib.pylab as plt\nimport netCDF4\nimport numpy as np\nimport os\nimport pprint\nimport sys\nimport time\n\nimport pysteps as stp\n\n# Verification settings\nverification = {\n    \"experiment_name\"   : \"pysteps_default\",\n    \"overwrite\"         : False,            # to recompute nowcasts\n    \"v_thresholds\"      : [0.1, 1.0],       # [mm/h]                 \n    \"v_leadtimes\"       : [10, 30, 60],     # [min]\n    \"v_accu\"            : None,             # [min]\n    \"seed\"              : 42,               # for reproducibility\n    \"doplot\"            : True,            # save figures\n    \"dosaveresults\"     : True              # save verification scores to csv\n}\n\n# Forecast settings\nforecast = {\n    \"n_lead_times\"      : 12,       # timesteps per nowcast\n    \"r_threshold\"       : 0.1,      # rain/no rain threshold [mm/h]\n    \"unit\"              : \"mm/h\",   # mm/h or dBZ\n    \"transformation\"    : \"dB\",     # None or dB \n    \"adjust_domain\"     : None      # None or square\n}\n\n# The experiment set-up\n## this includes tuneable parameters\nexperiment = {\n    ## the events           event start     event end       update cycle  data source\n    \"data\"              : [(\"201505151630\", \"201505151900\", 30,           \"mch\"),\n                           (\"201701311030\", \"201701311300\", 30,           \"mch\"),\n                           (\"201609281530\", \"201609281800\", 30,           \"fmi\"),\n                           (\"201705091130\", \"201705091400\", 30,           \"fmi\")],\n    \n    ## the methods\n    \"oflow_method\"      : [\"lucaskanade\"],      # lucaskanade, darts\n    \"adv_method\"        : [\"semilagrangian\"],   # semilagrangian, eulerian\n    \"nwc_method\"        : [\"steps\"],\n    \"noise_method\"      : [\"nonparametric\"],    # parametric, nonparametric, ssft\n    \"decomp_method\"     : [\"fft\"],\n    \n    ## the parameters\n    \"n_ens_members\"     : [20],\n    \"ar_order\"          : [2],\n    \"n_cascade_levels\"  : [6],\n    \"noise_adjustment\"  : [True],\n    \"conditional\"       : [False],\n    \"mask_method\"       : [\"incremental\"],      # obs, incremental, sprog\n}\n\n# Conditional parameters\n## parameters that can be directly related to other parameters\ndef cond_pars(pars):\n    for key in list(pars):\n        if key == \"oflow_method\":\n            if pars[key].lower() == \"darts\":  pars[\"n_prvs_times\"] = 9\n            else:                             pars[\"n_prvs_times\"] = 3\n        elif key.lower() == \"n_cascade_levels\":\n            if pars[key] == 1 : pars[\"bandpass_filter\"] = \"uniform\"\n            else:               pars[\"bandpass_filter\"] = \"gaussian\"\n        elif key.lower() == \"nwc_method\":\n            if pars[key] == \"extrapolation\" : pars[\"n_ens_members\"] = 1\n    return pars\n    \n# Prepare the list of all parameter sets of the verification\nparsets = [[]]\nfor _, items in experiment.items():\n    parsets = [parset+[item] for parset in parsets for item in items]\n\n# Now loop all parameter sets\nfor n, parset in enumerate(parsets):\n    \n    # Build parameter set\n    \n    p = {}\n    for m, key in enumerate(experiment.keys()):\n        p[key] = parset[m]\n    ## apply conditional parameters\n    p = cond_pars(p)\n    ## include all remaining parameters\n    p.update(verification)\n    p.update(forecast)\n    \n    print(\"************************\")\n    print(\"* Parameter set %02d/%02d: *\" % (n+1, len(parsets)))\n    print(\"************************\")\n    \n    pprint.pprint(p)\n    \n    # If necessary, build path to results\n    path_to_experiment = os.path.join(stp.rcparams.outputs.path_outputs, p[\"experiment_name\"])\n    # subdir with event date\n    path_to_nwc = os.path.join(path_to_experiment, '-'.join([p[\"data\"][0], p[\"data\"][3]]))\n    for key, item in p.items():\n\t\t# include only variables that change\n        if len(experiment.get(key,[None])) > 1 and key.lower() is not \"data\":\n            path_to_nwc = os.path.join(path_to_nwc, '-'.join([key, str(item)]))\n    try:\n        os.makedirs(path_to_nwc)\n    except FileExistsError:\n        pass\n        \n    # **************************************************************************\n    # NOWCASTING\n    # ************************************************************************** \n    \n    # Loop forecasts within given event using the prescribed update cycle interval\n\n    ## import data specifications\n    ds = stp.rcparams.data_sources[p[\"data\"][3]]\n    \n    if p[\"v_accu\"] is None:\n        p[\"v_accu\"] = ds.timestep\n    \n    # Loop forecasts for given event\n    startdate   = datetime.datetime.strptime(p[\"data\"][0], \"%Y%m%d%H%M\")\n    enddate     = datetime.datetime.strptime(p[\"data\"][1], \"%Y%m%d%H%M\")\n    countnwc = 0\n    while startdate + datetime.timedelta(minutes = p[\"n_lead_times\"]*ds.timestep) <= enddate:\n    \n        # filename of the nowcast netcdf\n        outfn = os.path.join(path_to_nwc, \"%s_nowcast.netcdf\" % startdate.strftime(\"%Y%m%d%H%M\"))\n    \n        ## check if results already exists\n        run_exist = False\n        if os.path.isfile(outfn):\n            fid = netCDF4.Dataset(outfn, 'r')\n            if fid.dimensions[\"time\"].size == p[\"n_lead_times\"]:\n                run_exist = True\n                if p[\"overwrite\"]:\n                    os.remove(outfn)\n                    run_exist = False    \n            else:\n                os.remove(outfn)\n                \n        if run_exist:\n            print(\"Nowcast %s_nowcast already exists in %s\" % (startdate.strftime(\"%Y%m%d%H%M\"),path_to_nwc))\n\n        else:\n            countnwc += 1\n            print(\"Computing the nowcast (%02d) ...\" % countnwc)\n            \n            print(\"Starttime: %s\" % startdate.strftime(\"%Y%m%d%H%M\"))\n            \n            ## redirect stdout to log file\n            logfn =  os.path.join(path_to_nwc, \"%s_log.txt\" % startdate.strftime(\"%Y%m%d%H%M\")) \n            print(\"Log: %s\" % logfn)\n            orig_stdout = sys.stdout\n            f = open(logfn, 'w')\n            sys.stdout = f\n            \n            print(\"*******************\")\n            print(\"* %s *****\" % startdate.strftime(\"%Y%m%d%H%M\"))\n            print(\"* Parameter set : *\")\n            pprint.pprint(p)\n            print(\"*******************\")\n            \n            print(\"--- Start of the run : %s ---\" % (datetime.datetime.now()))\n            \n            ## time\n            t0 = time.time()\n        \n            # Read inputs\n            print(\"Read the data...\")\n            \n            ## find radar field filenames\n            input_files = stp.io.find_by_date(startdate, ds.root_path, ds.path_fmt, ds.fn_pattern,\n                                              ds.fn_ext, ds.timestep, p[\"n_prvs_times\"])\n            \n    \n            ## read radar field files\n            importer    = stp.io.get_method(ds.importer, \"importer\")\n            R, _, metadata = stp.io.read_timeseries(input_files, importer, **ds.importer_kwargs)\n            metadata0 = metadata.copy()\n            metadata0[\"shape\"] = R.shape[1:]\n            \n            # Prepare input files\n            print(\"Prepare the data...\")\n            \n            ## if requested, make sure we work with a square domain\n            reshaper = stp.utils.get_method(p[\"adjust_domain\"])\n            R, metadata = reshaper(R, metadata)\n    \n            ## if necessary, convert to rain rates [mm/h]    \n            converter = stp.utils.get_method(\"mm/h\")\n            R, metadata = converter(R, metadata)\n            \n            ## threshold the data\n            R[R < p[\"r_threshold\"]] = 0.0\n            metadata[\"threshold\"] = p[\"r_threshold\"]\n            \n            ## convert the data\n            converter = stp.utils.get_method(p[\"unit\"])\n            R, metadata = converter(R, metadata)\n                \n            ## transform the data\n            transformer = stp.utils.get_method(p[\"transformation\"])\n            R, metadata = transformer(R, metadata)\n            \n            ## set NaN equal to zero\n            R[~np.isfinite(R)] = metadata[\"zerovalue\"]\n            \n            # Compute motion field\n            oflow_method = stp.motion.get_method(p[\"oflow_method\"])\n            UV = oflow_method(R)\n            \n            # Perform the nowcast       \n    \n            ## define the callback function to export the nowcast to netcdf\n            converter   = stp.utils.get_method(\"mm/h\")\n            def export(X):\n                ## convert to mm/h\n                X,_ = converter(X, metadata)\n                # readjust to initial domain shape\n                X,_ = reshaper(X, metadata, inverse=True)\n                # export to netcdf\n                stp.io.export_forecast_dataset(X, exporter)\n            \n            ## initialize netcdf file\n            incremental = \"timestep\" if p[\"nwc_method\"].lower() == \"steps\" else None\n            exporter = stp.io.initialize_forecast_exporter_netcdf(outfn, startdate,\n                              ds.timestep, p[\"n_lead_times\"], metadata0[\"shape\"], \n                              p[\"n_ens_members\"], metadata0, incremental=incremental)\n            \n            ## start the nowcast\n            nwc_method = stp.nowcasts.get_method(p[\"nwc_method\"])\n            R_fct = nwc_method(R, UV, p[\"n_lead_times\"], p[\"n_ens_members\"],\n                            p[\"n_cascade_levels\"], kmperpixel=metadata[\"xpixelsize\"]/1000, \n                            timestep=ds.timestep, R_thr=metadata[\"threshold\"], \n                            extrap_method=p[\"adv_method\"], \n                            decomp_method=p[\"decomp_method\"], \n                            bandpass_filter_method=p[\"bandpass_filter\"], \n                            noise_method=p[\"noise_method\"], \n                            noise_stddev_adj=p[\"noise_adjustment\"],\n                            ar_order=p[\"ar_order\"],conditional=p[\"conditional\"], \n                            mask_method=p[\"mask_method\"], callback=export, \n                            return_output=False, seed=p[\"seed\"])\n            \n            ## save results\n            stp.io.close_forecast_file(exporter)\n            R_fct = None\n            \n            # save log\n            print(\"--- End of the run : %s ---\" % (datetime.datetime.now()))\n            print(\"--- Total time : %s seconds ---\" % (time.time() - t0))\n            sys.stdout = orig_stdout\n            f.close()\n            \n        # next forecast\n        startdate += datetime.timedelta(minutes = p[\"data\"][2])\n    \n    # **************************************************************************\n    # VERIFICATION\n    # **************************************************************************  \n    \n    rankhists = {}\n    reldiags = {}\n    rocs = {}\n    for lt in p[\"v_leadtimes\"]:\n        rankhists[lt] = stp.verification.ensscores.rankhist_init(p[\"n_ens_members\"], p[\"r_threshold\"])\n        for thr in p[\"v_thresholds\"]:\n            reldiags[lt, thr]  = stp.verification.probscores.reldiag_init(thr)\n            rocs[lt, thr]      = stp.verification.probscores.ROC_curve_init(thr) \n    \n    # Loop the forecasts\n    startdate   = datetime.datetime.strptime(p[\"data\"][0], \"%Y%m%d%H%M\")\n    enddate     = datetime.datetime.strptime(p[\"data\"][1], \"%Y%m%d%H%M\")\n    countnwc = 0\n    while startdate + datetime.timedelta(minutes = p[\"n_lead_times\"]*ds.timestep) <= enddate:\n        \n        countnwc+=1\n        \n        print(\"Verifying the nowcast (%02d) ...\" % countnwc)\n        \n        # Read observations\n        \n        ## find radar field filenames\n        input_files = stp.io.find_by_date(startdate, ds.root_path, ds.path_fmt, ds.fn_pattern,\n                                          ds.fn_ext, ds.timestep, 0, p[\"n_lead_times\"])\n                                          \n        ## read radar field files\n        importer = stp.io.get_method(ds.importer, \"importer\")\n        R_obs, _, metadata_obs = stp.io.read_timeseries(input_files, importer, **ds.importer_kwargs)\n        R_obs = R_obs[1:,:,:]\n        metadata_obs[\"timestamps\"] = metadata_obs[\"timestamps\"][1:]\n        \n        ## if necessary, convert to rain rates [mm/h]   \n        converter = stp.utils.get_method(\"mm/h\")        \n        R_obs, metadata_obs = converter(R_obs, metadata_obs)  \n        \n        ## threshold the data\n        R_obs[R_obs < p[\"r_threshold\"]] = 0.0\n        metadata_obs[\"threshold\"] = p[\"r_threshold\"]\n            \n        # Load the nowcast\n        \n        ## filename of the nowcast netcdf\n        infn = os.path.join(path_to_nwc, \"%s_nowcast.netcdf\" % startdate.strftime(\"%Y%m%d%H%M\"))\n        \n        print(\"     read: %s\" % infn)\n            \n        ## read netcdf\n        R_fct, metadata_fct = stp.io.import_netcdf_pysteps(infn)\n        timestamps = metadata_fct[\"timestamps\"]\n        leadtimes = np.arange(1,len(timestamps)+1)*ds.timestep # min\n        metadata_fct[\"leadtimes\"] = leadtimes\n        \n        ## threshold the data\n        R_fct[R_fct < p[\"r_threshold\"]] = 0.0\n        metadata_fct[\"threshold\"] = p[\"r_threshold\"]\n        \n        ## if needed, compute accumulations\n        aggregator = stp.utils.get_method(\"accumulate\")\n        R_obs, metadata_obs = aggregator(R_obs, metadata_obs, p[\"v_accu\"])\n        R_fct, metadata_fct = aggregator(R_fct, metadata_fct, p[\"v_accu\"])\n        leadtimes = metadata_fct[\"leadtimes\"]\n        \n        # Do verification\n        \n        ## loop leadtimes\n        for i,lt in enumerate(p[\"v_leadtimes\"]):\n            \n            idlt = leadtimes == lt\n            \n            ## rank histogram\n            R_fct_ = np.vstack([R_fct[j, idlt, :, :].flatten() for j in range(p[\"n_ens_members\"])]).T\n            stp.verification.ensscores.rankhist_accum(rankhists[lt], \n                R_fct[:, idlt, :, :], R_obs[idlt, :, :])\n\n            ## loop thresholds\n            for thr in p[\"v_thresholds\"]:    \n                P_fct = 1.0*np.sum(R_fct_ >= thr, axis=1) / p[\"n_ens_members\"]\n                ## reliability diagram\n                stp.verification.probscores.reldiag_accum(reldiags[lt, thr], P_fct, R_obs[idlt, :, :].flatten())\n                ## roc curve\n                stp.verification.probscores.ROC_curve_accum(rocs[lt, thr], P_fct, R_obs[idlt, :, :].flatten())\n      \n        ## next forecast\n        startdate += datetime.timedelta(minutes = p[\"data\"][2])\n    \n    # Write out and plot verification scores for the event\n    for i,lt in enumerate(p[\"v_leadtimes\"]):\n    \n        idlt = leadtimes == lt\n        \n        ## write rank hist results to csv file\n        if verification[\"dosaveresults\"]:\n            fn = os.path.join(path_to_nwc, \"rankhist_%03d_%03d.csv\" % (lt, p[\"v_accu\"]))\n            with open(fn, 'w') as csv_file:\n                writer = csv.writer(csv_file)\n                for key, value in rankhists[lt].items():\n                   writer.writerow([key, value])\n        \n        ## plot rank hist\n        if verification[\"doplot\"]:\n            fig = plt.figure()\n            stp.verification.plot_rankhist(rankhists[lt], ax=fig.gca())\n            plt.savefig(os.path.join(path_to_nwc, \"rankhist_%03d_%03d.png\" % (lt, p[\"v_accu\"])), \n                    bbox_inches=\"tight\")\n            plt.close()\n        \n        for thr in p[\"v_thresholds\"]:\n        \n            if verification[\"dosaveresults\"]:\n                ## write rel diag results to csv file\n                fn = os.path.join(path_to_nwc, \"reldiag_%03d_%03d_thr%.1f.csv\" % (lt, p[\"v_accu\"], thr))\n                with open(fn, 'w') as csv_file:\n                    writer = csv.writer(csv_file)\n                    for key, value in reldiags[lt, thr].items():\n                       writer.writerow([key, value])\n                \n                ## write roc curve results to csv file                \n                fn = os.path.join(path_to_nwc, \"roc_%03d_%03d_thr%.1f.csv\" % (lt, p[\"v_accu\"], thr))\n                with open(fn, 'w') as csv_file:\n                    writer = csv.writer(csv_file)\n                    for key, value in rocs[lt, thr].items():\n                       writer.writerow([key, value])\n        \n            if verification[\"doplot\"]:\n                fig = plt.figure()\n                stp.verification.plot_reldiag(reldiags[lt, thr], ax=fig.gca())\n                plt.savefig(os.path.join(path_to_nwc, \"reldiag_%03d_%03d_thr%.1f.png\" % (lt, p[\"v_accu\"], thr)), \n                        bbox_inches=\"tight\")\n                plt.close()\n                \n                fig = plt.figure()\n                stp.verification.plot_ROC(rocs[lt, thr], ax=fig.gca())\n                plt.savefig(os.path.join(path_to_nwc, \"roc_%03d_%03d_thr%.1f.png\" % (lt, p[\"v_accu\"], thr)), \n                        bbox_inches=\"tight\")\n                plt.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}